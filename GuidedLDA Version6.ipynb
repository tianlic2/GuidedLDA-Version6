{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets (excludes replies): 6501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.corpora.dictionary:adding document #0 to Dictionary(0 unique tokens: [])\n",
      "INFO:gensim.corpora.dictionary:built Dictionary(1566 unique tokens: ['along', 'august', 'biggest', 'brought', 'celebr']...) from 760 documents (total 2689 corpus positions)\n",
      "INFO:gensim.models.ldamodel:using autotuned alpha, starting with [0.5, 0.5]\n",
      "INFO:gensim.models.ldamodel:using symmetric eta at 0.5\n",
      "INFO:gensim.models.ldamodel:using serial LDA version on this node\n",
      "INFO:gensim.models.ldamodel:running online (single-pass) LDA training, 2 topics, 1 passes over the supplied corpus of 760 documents, updating model once every 760 documents, evaluating perplexity every 760 documents, iterating 50x with a convergence threshold of 0.001000\n",
      "WARNING:gensim.models.ldamodel:too few updates, training might not converge; consider increasing the number of passes or iterations to improve accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of tweets within 17 topics: 5667\n",
      "The number of other tweets: 760\n",
      "The number of non English tweets: 74\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:gensim.models.ldamodel:-8.250 per-word bound, 304.5 perplexity estimate based on a held-out corpus of 760 documents with 2689 words\n",
      "INFO:gensim.models.ldamodel:PROGRESS: pass 0, at document #760/760\n",
      "INFO:gensim.models.ldamodel:optimized alpha [0.6629571, 0.6725566]\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.663): 0.009*\"food\" + 0.006*\"great\" + 0.005*\"make\" + 0.005*\"year\" + 0.005*\"today\" + 0.004*\"look\" + 0.004*\"memphi\" + 0.004*\"meet\" + 0.004*\"time\" + 0.004*\"come\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.673): 0.014*\"cleanmeat\" + 0.012*\"food\" + 0.008*\"world\" + 0.007*\"gt\" + 0.007*\"futureoffood\" + 0.005*\"culturedmeat\" + 0.005*\"make\" + 0.005*\"great\" + 0.004*\"come\" + 0.004*\"time\"\n",
      "INFO:gensim.models.ldamodel:topic diff=0.660535, rho=1.000000\n",
      "INFO:gensim.models.ldamodel:topic #0 (0.663): 0.009*\"food\" + 0.006*\"great\" + 0.005*\"make\" + 0.005*\"year\" + 0.005*\"today\" + 0.004*\"look\" + 0.004*\"memphi\" + 0.004*\"meet\" + 0.004*\"time\" + 0.004*\"come\" + 0.004*\"think\" + 0.003*\"world\" + 0.003*\"chang\" + 0.003*\"well\" + 0.003*\"meat\" + 0.003*\"cleanmeat\" + 0.003*\"foodtech\" + 0.003*\"futureoffood\" + 0.003*\"go\" + 0.003*\"good\" + 0.003*\"get\" + 0.003*\"scienc\" + 0.003*\"would\" + 0.003*\"beyond\" + 0.003*\"best\" + 0.003*\"peopl\" + 0.002*\"next\" + 0.002*\"know\" + 0.002*\"featur\" + 0.002*\"amaz\" + 0.002*\"interest\" + 0.002*\"culturedmeat\" + 0.002*\"order\" + 0.002*\"arriv\" + 0.002*\"sure\" + 0.002*\"pitch\" + 0.002*\"demo\" + 0.002*\"take\" + 0.002*\"still\" + 0.002*\"wait\" + 0.002*\"inspir\" + 0.002*\"produc\" + 0.002*\"littl\" + 0.002*\"love\" + 0.002*\"friend\" + 0.002*\"way\" + 0.002*\"start\" + 0.002*\"answer\" + 0.002*\"result\" + 0.002*\"piec\"\n",
      "INFO:gensim.models.ldamodel:topic #1 (0.673): 0.014*\"cleanmeat\" + 0.012*\"food\" + 0.008*\"world\" + 0.007*\"gt\" + 0.007*\"futureoffood\" + 0.005*\"culturedmeat\" + 0.005*\"make\" + 0.005*\"great\" + 0.004*\"come\" + 0.004*\"time\" + 0.004*\"memphi\" + 0.004*\"take\" + 0.004*\"want\" + 0.004*\"meat\" + 0.004*\"next\" + 0.003*\"would\" + 0.003*\"start\" + 0.003*\"good\" + 0.003*\"year\" + 0.003*\"look\" + 0.003*\"chang\" + 0.003*\"love\" + 0.003*\"think\" + 0.003*\"today\" + 0.003*\"worldsfirstculturedmeatbal\" + 0.002*\"like\" + 0.002*\"featur\" + 0.002*\"idea\" + 0.002*\"peopl\" + 0.002*\"beyond\" + 0.002*\"germani\" + 0.002*\"websit\" + 0.002*\"scienc\" + 0.002*\"heard\" + 0.002*\"milk\" + 0.002*\"day\" + 0.002*\"cellag\" + 0.002*\"ch\" + 0.002*\"cellbasedmeat\" + 0.002*\"finless\" + 0.002*\"friend\" + 0.002*\"nice\" + 0.002*\"kweekvle\" + 0.002*\"readi\" + 0.002*\"pretti\" + 0.002*\"benefit\" + 0.002*\"pitch\" + 0.002*\"sure\" + 0.002*\"could\" + 0.002*\"much\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.009*\"food\" + 0.006*\"great\" + 0.005*\"make\" + 0.005*\"year\" + 0.005*\"today\" '\n",
      "  '+ 0.004*\"look\" + 0.004*\"memphi\" + 0.004*\"meet\" + 0.004*\"time\" + '\n",
      "  '0.004*\"come\" + 0.004*\"think\" + 0.003*\"world\" + 0.003*\"chang\" + 0.003*\"well\" '\n",
      "  '+ 0.003*\"meat\" + 0.003*\"cleanmeat\" + 0.003*\"foodtech\" + '\n",
      "  '0.003*\"futureoffood\" + 0.003*\"go\" + 0.003*\"good\" + 0.003*\"get\" + '\n",
      "  '0.003*\"scienc\" + 0.003*\"would\" + 0.003*\"beyond\" + 0.003*\"best\" + '\n",
      "  '0.003*\"peopl\" + 0.002*\"next\" + 0.002*\"know\" + 0.002*\"featur\" + 0.002*\"amaz\" '\n",
      "  '+ 0.002*\"interest\" + 0.002*\"culturedmeat\" + 0.002*\"order\" + 0.002*\"arriv\" + '\n",
      "  '0.002*\"sure\" + 0.002*\"pitch\" + 0.002*\"demo\" + 0.002*\"take\" + 0.002*\"still\" '\n",
      "  '+ 0.002*\"wait\" + 0.002*\"inspir\" + 0.002*\"produc\" + 0.002*\"littl\" + '\n",
      "  '0.002*\"love\" + 0.002*\"friend\" + 0.002*\"way\" + 0.002*\"start\" + '\n",
      "  '0.002*\"answer\" + 0.002*\"result\" + 0.002*\"piec\"'),\n",
      " (1,\n",
      "  '0.014*\"cleanmeat\" + 0.012*\"food\" + 0.008*\"world\" + 0.007*\"gt\" + '\n",
      "  '0.007*\"futureoffood\" + 0.005*\"culturedmeat\" + 0.005*\"make\" + 0.005*\"great\" '\n",
      "  '+ 0.004*\"come\" + 0.004*\"time\" + 0.004*\"memphi\" + 0.004*\"take\" + '\n",
      "  '0.004*\"want\" + 0.004*\"meat\" + 0.004*\"next\" + 0.003*\"would\" + 0.003*\"start\" '\n",
      "  '+ 0.003*\"good\" + 0.003*\"year\" + 0.003*\"look\" + 0.003*\"chang\" + 0.003*\"love\" '\n",
      "  '+ 0.003*\"think\" + 0.003*\"today\" + 0.003*\"worldsfirstculturedmeatbal\" + '\n",
      "  '0.002*\"like\" + 0.002*\"featur\" + 0.002*\"idea\" + 0.002*\"peopl\" + '\n",
      "  '0.002*\"beyond\" + 0.002*\"germani\" + 0.002*\"websit\" + 0.002*\"scienc\" + '\n",
      "  '0.002*\"heard\" + 0.002*\"milk\" + 0.002*\"day\" + 0.002*\"cellag\" + 0.002*\"ch\" + '\n",
      "  '0.002*\"cellbasedmeat\" + 0.002*\"finless\" + 0.002*\"friend\" + 0.002*\"nice\" + '\n",
      "  '0.002*\"kweekvle\" + 0.002*\"readi\" + 0.002*\"pretti\" + 0.002*\"benefit\" + '\n",
      "  '0.002*\"pitch\" + 0.002*\"sure\" + 0.002*\"could\" + 0.002*\"much\"')]\n"
     ]
    }
   ],
   "source": [
    "#read data(exclude replies)\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import SnowballStemmer\n",
    "import pandas as pd\n",
    "\n",
    "text = pd.read_csv('Jan6(excludes replies).csv')\n",
    "print('The number of tweets (excludes replies):',len(text))\n",
    "#Text cleaning\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "import re\n",
    "stemmer = SnowballStemmer('english')\n",
    "porter = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words += ['cultured','clean','cultivated','meat']\n",
    "b = []\n",
    "for i,u in text.iterrows():\n",
    "    a = []\n",
    "    word =''\n",
    "    for words in str(u['tweets']).split():\n",
    "        if '@' not in words: #remove @users\n",
    "            words = words.replace('#','') #remove hashtag symbol\n",
    "            if '#' not in words:\n",
    "                if 'http' not in words: #remove URLs\n",
    "                    if'&amp' not in words: #remove symbol\n",
    "                        words = words.lower()# lower form\n",
    "                        words = re.sub(r'[^a-zA-Z]', ' ', words) #replace non-alphabets characters with space. From \"can't\" to \"can t\"\n",
    "                        if len(words)>3:\n",
    "                            word += (words+' ')\n",
    "    doc = ''\n",
    "    for token in word.split():\n",
    "        if len(token) >1:\n",
    "            if token not in stop_words:\n",
    "                token = porter.stem(token) #root form\n",
    "                doc += (token+' ')\n",
    "    b.append(doc)\n",
    "text['processed']=[i for i in b]\n",
    "text.to_csv('kk.csv')\n",
    "\n",
    "\n",
    "\n",
    "import guidedlda\n",
    "import numpy as np\n",
    "import gensim\n",
    "topic_tweets=[]\n",
    "other_tweets=[]\n",
    "topic_tweets_Company = []\n",
    "other_tweets_processed = []\n",
    "non_english_tweets = []\n",
    "\n",
    "keywords_list = ['environ','environment','carbon','climat','greenhous','emiss','better','planet','save','reduc',\n",
    "                   'system','futur','land','plastic','climatechang', #0 Environmental Impact\n",
    "                   'plant','vegan','vegetarian','anim','altern','protein','plantbas', #1 Vegetarian\n",
    "                   'animal','without','slaughter','cruelti','welfar','kill','cow','human','farm','save',#2 Animal Welfare\n",
    "                   'consumpt','popul','demand','secur','wast','grow','global','sustain','need','solut',\n",
    "                 'consum','eat','growth','feed','gluttoni',#3 Food Security\n",
    "                   'antibiot','antimicrobi','resist','safeti','contamin','free','health','overus',\n",
    "                 'diseas','use','metal','bacteria','regulatori','usda','fda','safe','joint','label',#4 Food Safety\n",
    "                   'public','health','pandem','covid','risk','coronaviru',# 5 Public Health\n",
    "                   'industri','suppli','convent','regular','system','chain','game','changer','compani',#6 Food Industry\n",
    "                   'market','consum','store','groceri','product','demand','grow','launch','scale','cost',\n",
    "                 'soon','sell', #7 Market\n",
    "                   'seafood','sea','ocean','fish','aquacultur','shrimp','salmon','wild','lobster','tuna',\n",
    "                 'sushi','crustacean',#8 Seafood\n",
    "                   'tast','tender','textur','juici','test','delici','culinari','favorit',\n",
    "                   'chicken','duck','poultri','egg','burger','steak','meatbal','beef','sausag','tasti',#9 Poultry and Meat\n",
    "                   'stem','muscl','divis','biolog','cellular','technolog','agricultur','creat','made',\n",
    "                 'lab','cell','biotech',#10 Process\n",
    "                   'seri','fund','rais','invest','investor','dollar','pound','round','startup',\n",
    "                   'opportun','first','seed','isra','acceler','announc','happi','thrill','excit','pleas','contribut',\n",
    "                 'honor','proud','statement', #11 Fundraising Announcement\n",
    "                   'thank','support','shoutout','help','shout','question','congrat','congratul',\n",
    "                 'share','mention', #12 Appreciation\n",
    "                   'confer','regist','live','symposium','stream','livestream','summit','co','founder',\n",
    "                 'talk','speak','convers','ceo','tomorrow','tune', #13 Conference and Summit\n",
    "                   'check','post','paper','interview','articl','blog','news','break','read',\n",
    "                 'latest','watch','podcast','listen','episod','stori','campaign','coverag','video','singapor','discuss','vote','panel','chat',\n",
    "                   'scientist','ceo','event','media','report','cover','bbc','present','innov', #14 Media\n",
    "                   'hire','join','team','bring','welcom','work','appli','research','specialist',\n",
    "                 'student','career','posit',#15 Hiring Information\n",
    "                   'congrat','congratul','list','award','winner','finalist','partner','prize']#16 Congratulations\n",
    "non_english_list = ['temiz','rkiy','erik','nda','konu','dan','da','ba','temiz','al','viand','para','na','dann','uft','laboratorio','dieser','kalbimi',\n",
    "                   'restoranda','evento','mayo','komo','ind','tica','futuro','sonra','yla','cre','ili','daki',\n",
    "                   'zaman']\n",
    "for index,i in text.iterrows():\n",
    "    count = 0\n",
    "    non_english_count = 0\n",
    "    for word in i['processed'].split():\n",
    "        if word in keywords_list:\n",
    "            count+=1 #if any keyword occur in a tweet, the tweet may belong to one of the above themes\n",
    "        elif word in non_english_list:\n",
    "            non_english_count+=1\n",
    "    if count !=0: #if none of the keywords occur in a tweet, the tweet doesnot belong to any themes we found\n",
    "        topic_tweets.append(i['processed'])\n",
    "        topic_tweets_Company.append(i['Company'])\n",
    "        \n",
    "    elif non_english_count != 0:\n",
    "        non_english_tweets.append(i['tweets'])\n",
    "    else:\n",
    "        other_tweets.append(i['tweets'])\n",
    "        other_tweets_processed.append(i['processed'])\n",
    "other = pd.DataFrame(data= [i for i in other_tweets],columns=['tweets'])\n",
    "other['processed'] = [i for i in other_tweets_processed]\n",
    "\n",
    "print('The number of tweets within 17 topics:',len(topic_tweets))\n",
    "print('The number of other tweets:',len(other_tweets))\n",
    "print('The number of non English tweets:',len(non_english_tweets))\n",
    "\n",
    "#unigram LDA\n",
    "from pprint import pprint\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "unigram = []\n",
    "unigram_list = []\n",
    "for index, i in other.iterrows():\n",
    "    unigram=[]\n",
    "    for word in i['processed'].split():\n",
    "        unigram.append(word)\n",
    "    unigram_list.append(unigram)\n",
    "data_words = [i for i in unigram_list]\n",
    "id2word = corpora.Dictionary(data_words)\n",
    "texts = data_words\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, random_state=10,\n",
    "                                            alpha='auto', per_word_topics=True)\n",
    "pprint(lda_model.print_topics(num_words=50,num_topics=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:guidedlda:n_documents: 5667\n",
      "INFO:guidedlda:vocab_size: 7255\n",
      "INFO:guidedlda:n_words: 66323\n",
      "INFO:guidedlda:n_topics: 18\n",
      "INFO:guidedlda:n_iter: 200\n",
      "INFO:guidedlda:<0> log likelihood: -782197\n",
      "INFO:guidedlda:<10> log likelihood: -556313\n",
      "INFO:guidedlda:<20> log likelihood: -543549\n",
      "INFO:guidedlda:<30> log likelihood: -538755\n",
      "INFO:guidedlda:<40> log likelihood: -536280\n",
      "INFO:guidedlda:<50> log likelihood: -534708\n",
      "INFO:guidedlda:<60> log likelihood: -533926\n",
      "INFO:guidedlda:<70> log likelihood: -533306\n",
      "INFO:guidedlda:<80> log likelihood: -532225\n",
      "INFO:guidedlda:<90> log likelihood: -531855\n",
      "INFO:guidedlda:<100> log likelihood: -531635\n",
      "INFO:guidedlda:<110> log likelihood: -530764\n",
      "INFO:guidedlda:<120> log likelihood: -530200\n",
      "INFO:guidedlda:<130> log likelihood: -530314\n",
      "INFO:guidedlda:<140> log likelihood: -530139\n",
      "INFO:guidedlda:<150> log likelihood: -529612\n",
      "INFO:guidedlda:<160> log likelihood: -529626\n",
      "INFO:guidedlda:<170> log likelihood: -529222\n",
      "INFO:guidedlda:<180> log likelihood: -528810\n",
      "INFO:guidedlda:<190> log likelihood: -528711\n",
      "INFO:guidedlda:<199> log likelihood: -528971\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Topic: 0\n",
      "0.0419*chang  0.0299*climat  0.0294*world  0.0279*anim  0.0272*food  0.0227*better  0.0155*could  0.0147*environ  0.0142*environment  0.014*futur  0.0127*agricultur  0.0125*produc  0.0122*impact  0.0122*eat  0.0117*water  0.0115*human  0.0115*less  0.011*planet  0.011*reduc  0.011*sustain  0.01*use  0.01*want  0.0097*love  0.009*earth  0.0087*climatechang  0.0087*livestock  0.0082*solv  0.0082*solut  0.0082*without  0.008*problem  0.008*convent  0.0077*land  0.0077*make  0.0075*system  0.0067*take  0.0067*issu  0.0067*emiss  0.0062*farm  0.006*diet  0.0057*real  \n",
      "\n",
      "Topic: 1\n",
      "0.0476*protein  0.0467*plant  0.044*food  0.0438*base  0.0386*altern  0.028*plantbas  0.0223*burger  0.0223*vegan  0.0174*industri  0.0152*beyond  0.012*next  0.0103*dairi  0.0101*cubiq  0.0101*foodtech  0.0098*anim  0.009*show  0.0084*offer  0.0079*go  0.0076*milk  0.0076*smart  0.0071*tast  0.0065*fat  0.0065*imposs  0.0063*get  0.0063*ingredi  0.0063*omega  0.0063*say  0.0063*invest  0.006*replac  0.0057*includ  0.0057*level  0.0057*improv  0.0052*come  0.0052*stay  0.0052*opportun  0.0046*call  0.0046*learn  0.0046*landscap  0.0046*alternativeprotein  0.0046*look  \n",
      "\n",
      "Topic: 2\n",
      "0.0948*anim  0.051*without  0.0331*slaughter  0.0286*free  0.0273*make  0.024*real  0.0228*grow  0.0176*cleanmeat  0.0152*need  0.0146*save  0.0143*kill  0.014*world  0.0134*harm  0.0128*help  0.0122*peopl  0.0122*cell  0.0119*produc  0.0119*want  0.0103*culturedmeat  0.01*vegan  0.01*cow  0.0097*chicken  0.0085*come  0.0082*supermeat  0.0082*planet  0.0082*cruelti  0.0076*gt  0.0073*check  0.0073*directli  0.0073*made  0.0064*rais  0.0058*startup  0.0055*good  0.0055*develop  0.0052*viand  0.0052*realiti  0.0052*environ  0.0046*think  0.0046*enough  0.0043*better  \n",
      "\n",
      "Topic: 3\n",
      "0.0638*food  0.0597*sustain  0.0226*world  0.0217*global  0.0178*futur  0.0174*innov  0.0165*system  0.0156*feed  0.0149*product  0.0133*work  0.0133*technolog  0.0133*grow  0.0126*creat  0.0123*planet  0.0123*seafood  0.0121*peopl  0.0103*solut  0.0098*challeng  0.0087*healthi  0.0085*protein  0.0085*human  0.0085*mission  0.0085*billion  0.0085*help  0.0085*way  0.0075*need  0.0075*tech  0.0073*provid  0.0071*save  0.0071*consum  0.0069*transform  0.0069*import  0.0066*secur  0.0064*toward  0.0062*altern  0.0062*nutrit  0.0059*share  0.0059*potenti  0.0059*sourc  0.0059*access  \n",
      "\n",
      "Topic: 4\n",
      "0.0215*sustain  0.0207*help  0.0185*free  0.0177*delici  0.0172*antibiot  0.0159*word  0.0146*give  0.0146*need  0.0134*make  0.0116*revolut  0.0116*know  0.0112*spread  0.0095*use  0.0095*podcast  0.009*time  0.009*vote  0.0082*day  0.0078*one  0.0078*biolog  0.0078*healthier  0.0073*eat  0.0069*cook  0.0069*agricultur  0.0069*interest  0.0065*power  0.0065*ferment  0.006*right  0.006*natur  0.0056*meal  0.0056*perfect  0.0056*finless  0.0056*progress  0.0052*particip  0.0052*contamin  0.0052*resist  0.0052*stop  0.0047*would  0.0047*centuri  0.0047*synthet  0.0047*control  \n",
      "\n",
      "Topic: 5\n",
      "0.0657*cleanmeat  0.0448*culturedmeat  0.0279*product  0.0215*cellbasedmeat  0.0192*industri  0.0186*cellag  0.017*futur  0.0167*cultivatedmeat  0.0167*supermeat  0.0157*futureoffood  0.0141*regul  0.0141*compani  0.0112*today  0.0103*support  0.0096*mean  0.0086*creat  0.0083*safe  0.0083*regulatori  0.008*label  0.008*biotech  0.0074*cellbas  0.0074*learn  0.0074*process  0.007*cellularagricultur  0.007*tradit  0.0067*scale  0.0067*convent  0.0067*sign  0.0067*cell  0.0067*usda  0.0067*joint  0.0064*commerci  0.0061*futurefood  0.0058*technolog  0.0058*growth  0.0058*goodfood  0.0054*job  0.0054*tasti  0.0051*progress  0.0048*expert  \n",
      "\n",
      "Topic: 6\n",
      "0.023*anim  0.0203*like  0.0194*covid  0.0161*health  0.0161*pandem  0.014*consum  0.0134*farm  0.0128*much  0.0125*read  0.0125*need  0.0123*peopl  0.0117*report  0.0111*time  0.0111*eat  0.0108*would  0.0096*impact  0.0096*human  0.0093*live  0.009*cultivatedmeat  0.0078*industri  0.0072*coronaviru  0.0072*studi  0.0072*stop  0.0072*public  0.0069*mani  0.0069*risk  0.0066*might  0.0063*never  0.0063*articl  0.0063*highlight  0.006*even  0.006*caus  0.006*book  0.006*found  0.006*want  0.006*right  0.0057*ever  0.0057*percent  0.0057*long  0.0057*speci  \n",
      "\n",
      "Topic: 7\n",
      "0.0258*industri  0.0247*year  0.0201*fish  0.0179*like  0.0164*good  0.0153*look  0.0147*suppli  0.0133*thing  0.0133*farm  0.013*food  0.0119*contribut  0.0119*come  0.0116*chain  0.0111*huge  0.0108*investor  0.0108*need  0.0108*today  0.0102*time  0.0099*realli  0.0094*compani  0.0091*thought  0.0088*go  0.0088*say  0.0085*global  0.0085*futur  0.0085*move  0.0079*know  0.0079*would  0.0079*disrupt  0.0077*doubl  0.0074*whole  0.0071*great  0.0071*away  0.0065*peopl  0.0062*lead  0.0062*talk  0.0062*demand  0.0062*take  0.0062*chang  0.006*also  \n",
      "\n",
      "Topic: 8\n",
      "0.0478*product  0.0459*market  0.0225*base  0.0223*plant  0.0204*year  0.0177*cost  0.0166*bring  0.0153*scale  0.0121*cell  0.011*global  0.0105*consum  0.0105*first  0.0102*report  0.0102*growth  0.0094*plantbas  0.0094*grow  0.0089*produc  0.0086*facil  0.0078*could  0.0075*qualiti  0.0072*manufactur  0.0072*larg  0.007*reach  0.007*take  0.0064*work  0.0062*wait  0.0059*price  0.0059*plan  0.0056*import  0.0056*demand  0.0054*billion  0.0054*high  0.0054*say  0.0051*consumpt  0.0051*last  0.0051*store  0.0051*avail  0.0051*develop  0.0051*tech  0.0048*drop  \n",
      "\n",
      "Topic: 9\n",
      "0.0413*seafood  0.0343*fish  0.0292*shrimp  0.0259*singapor  0.0257*shiok  0.0238*ocean  0.0221*shiokmeat  0.02*cell  0.0189*salmon  0.0184*asia  0.0176*futureoffood  0.0165*startup  0.0135*base  0.013*meat  0.0127*tast  0.0122*sushi  0.0119*aquacultur  0.0119*sustain  0.0105*cellag  0.01*lobster  0.0095*cellbasedmeat  0.0086*cellbas  0.0086*cellularagricultur  0.0084*produc  0.0078*cellular  0.0076*cleanmeat  0.0073*tuna  0.0068*wild  0.0068*stemcel  0.0065*foodtech  0.0065*first  0.0065*chef  0.0059*crustacean  0.0057*know  0.0057*bluenalu  0.0054*sashimi  0.0054*also  0.0054*healthi  0.0051*nigiri  0.0051*scientist  \n",
      "\n",
      "Topic: 10\n",
      "0.0677*grown  0.0549*steak  0.0533*first  0.0489*lab  0.0305*chicken  0.0275*tast  0.0261*world  0.024*farm  0.0219*cell  0.0209*aleph  0.0172*culturedmeat  0.017*beef  0.0168*cleanmeat  0.0126*startup  0.0116*isra  0.01*produc  0.0093*slaughter  0.0093*made  0.0091*creat  0.0091*like  0.0084*compani  0.0084*free  0.0081*textur  0.0077*space  0.0074*duck  0.0074*israel  0.0072*meatbal  0.0067*soon  0.0065*start  0.0063*pork  0.0063*cook  0.0063*experi  0.0061*look  0.0058*make  0.0056*test  0.0056*burger  0.0056*success  0.0054*shape  0.0054*minut  0.0054*come  \n",
      "\n",
      "Topic: 11\n",
      "0.1117*cell  0.0812*base  0.0258*agricultur  0.0203*cellular  0.0183*food  0.0161*made  0.0161*seafood  0.0151*meat  0.0134*product  0.0129*grow  0.0124*compani  0.0104*anim  0.0102*produc  0.0097*use  0.0097*start  0.0097*stem  0.0094*startup  0.0092*make  0.0092*like  0.0084*develop  0.0082*protein  0.0082*process  0.0079*grown  0.0077*plant  0.0077*innov  0.0077*muscl  0.0074*tech  0.0074*technolog  0.0074*research  0.0074*space  0.0072*lab  0.0067*explain  0.0057*bluenalu  0.0057*meet  0.0054*think  0.0052*cut  0.005*differ  0.005*scale  0.005*biotech  0.0047*sandhya  \n",
      "\n",
      "Topic: 12\n",
      "0.0449*startup  0.0353*invest  0.0321*rais  0.0302*foodtech  0.0283*million  0.0283*fund  0.0279*compani  0.0253*announc  0.0197*round  0.0147*start  0.0143*isra  0.0143*cellbas  0.0143*seri  0.0131*food  0.0112*product  0.011*investor  0.0108*futureoffood  0.0101*innov  0.0101*seed  0.0098*acceler  0.0094*farm  0.0094*close  0.0089*tech  0.0082*make  0.0082*ventur  0.0077*launch  0.0077*full  0.0075*agtech  0.0075*didier  0.0075*aleph  0.0073*plantbas  0.0073*toubia  0.0073*lead  0.007*israel  0.007*space  0.0068*first  0.0068*congratul  0.0068*culturedmeat  0.0063*part  0.0063*protein  \n",
      "\n",
      "Topic: 13\n",
      "0.0502*thank  0.0235*happi  0.0224*join  0.0222*support  0.0187*futur  0.0164*campaign  0.0161*work  0.0151*year  0.0136*memphi  0.0129*forward  0.0126*meat  0.0121*love  0.0116*help  0.0114*movement  0.0108*excit  0.0108*team  0.0096*think  0.0093*make  0.0088*question  0.0088*look  0.0088*friend  0.0088*pleas  0.0081*part  0.0081*mani  0.0081*inspir  0.0081*want  0.0078*better  0.0076*ask  0.0076*back  0.0076*much  0.0071*mention  0.0071*well  0.0068*peopl  0.0068*great  0.0068*chanc  0.0066*share  0.0066*check  0.0066*celebr  0.0063*commun  0.0063*follow  \n",
      "\n",
      "Topic: 14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0312*food  0.0293*speak  0.0287*futur  0.024*join  0.0212*panel  0.0191*founder  0.0181*confer  0.0175*discuss  0.0157*talk  0.0138*event  0.0126*tomorrow  0.0122*live  0.0122*week  0.0118*summit  0.0118*today  0.0112*innov  0.011*th  0.0104*ceo  0.01*come  0.0098*co  0.0094*present  0.0088*watch  0.0086*meet  0.0081*foodtech  0.0077*excit  0.0071*next  0.0069*goodfoodconfer  0.0069*pitch  0.0067*tune  0.0065*regist  0.0063*host  0.0061*onlin  0.0061*speaker  0.0057*june  0.0055*pm  0.0053*technolog  0.0053*leader  0.0053*cultivatedmeat  0.0051*hear  0.0049*happen  \n",
      "\n",
      "Topic: 15\n",
      "0.0355*team  0.0243*research  0.0201*work  0.0189*scienc  0.0184*food  0.0164*hire  0.0156*scientist  0.0154*excit  0.0149*join  0.0149*meat  0.0142*look  0.0124*engin  0.0124*develop  0.0114*welcom  0.0112*appli  0.0109*pleas  0.0102*futur  0.0099*co  0.0094*make  0.0079*meet  0.0077*check  0.0077*want  0.0075*learn  0.0075*member  0.0075*founder  0.0072*board  0.0072*role  0.007*cultur  0.0067*today  0.0067*passion  0.0067*offic  0.0065*bring  0.0065*biolog  0.0065*recent  0.0062*shiok  0.0062*proud  0.006*director  0.006*scientif  0.006*experi  0.0057*field  \n",
      "\n",
      "Topic: 16\n",
      "0.0234*world  0.0231*list  0.0224*excit  0.0192*team  0.0172*congrat  0.0159*innov  0.0156*year  0.0146*proud  0.0146*compani  0.014*honor  0.014*chang  0.0127*part  0.0117*amaz  0.0114*award  0.0111*step  0.0111*industri  0.0107*congratul  0.0104*huge  0.0101*share  0.0098*week  0.0094*select  0.0091*challeng  0.0088*incred  0.0088*work  0.0085*investor  0.0085*togeth  0.0081*meatabl  0.0078*last  0.0078*great  0.0075*well  0.0075*bring  0.0072*next  0.0072*sinc  0.0072*winner  0.0072*best  0.0072*friend  0.0065*start  0.0062*finalist  0.0059*approach  0.0055*final  \n",
      "\n",
      "Topic: 17\n",
      "0.0418*thank  0.0335*featur  0.0327*great  0.0287*check  0.0229*articl  0.0226*latest  0.02*interview  0.02*meat  0.0189*futur  0.0173*news  0.017*video  0.0162*read  0.0154*talk  0.0146*stori  0.0144*podcast  0.0138*post  0.013*piec  0.013*cover  0.0117*listen  0.0109*episod  0.0106*amaz  0.0104*futureoffood  0.0101*memphi  0.0096*share  0.0093*watch  0.0088*blog  0.008*scienc  0.008*discuss  0.0075*ceo  0.0072*industri  0.0072*cool  0.0069*includ  0.0069*full  0.0069*food  0.0067*magazin  0.0067*coverag  0.0061*cleanmeat  0.0061*today  0.0056*vision  0.0053*brian  "
     ]
    }
   ],
   "source": [
    "seed_topic_list = [['environ','environment','carbon','climat','greenhous','emiss','better','planet','save','reduc',\n",
    "                   'system','futur','land','ecolog','plastic','climatechang'], #0 Environmental Impact\n",
    "                   ['plant','vegan','vegetarian','anim','altern','protein','plantbas'], #1 Vegetarian\n",
    "                   ['animal','without','slaughter','cruelti','welfar','kill','cow','human','farm','save'],#2 Animal Welfare\n",
    "                   ['consumpt','popul','demand','secur','wast','grow','global','sustain','need',\n",
    "                   'consum','eat','growth','feed','gluttoni'],#3 Food Security\n",
    "                   ['antibiot','antimicrobi','resist','safeti','contamin','free','health','overus',\n",
    "                   'diseas','use','metal','bacteria','regulatori','usda','fda','safe','joint','label'],#4 Food Safety\n",
    "                   ['regulatori','usda','fda','safe','joint','label'],#5 Regulations\n",
    "                   ['public','health','pandem','covid','risk','coronaviru'],# 6 Public Health\n",
    "                   ['industri','suppli','convent','regular','system','chain','game','changer','compani'],#7 Food Industry\n",
    "                   ['market','consum','store','groceri','product','demand','grow','launch','scale','cost','soon','sell'], #8 Market\n",
    "                   ['seafood','sea','ocean','fish','aquacultur','shrimp','salmon','wild','lobster','tuna','sushi','crustacean'],#9 Seafood\n",
    "                   ['chicken','duck','poultri','egg','burger','steak','meatbal','beef','sausag',\n",
    "                    'tast','tender','textur','juici','test','delici','culinari','favorit','tasti'],#10 Poultry and Meat\n",
    "                   ['stem','muscl','divis','biolog','cellular','technolog','agricultur','creat','made','lab','cell','biotech','tech'],#11 Process\n",
    "                   ['seri','fund','rais','invest','investor','dollar','pound','round','startup',\n",
    "                   'opportun','first','seed','isra','acceler','announc','happi','thrill','excit','pleas','contribut','honor','proud','statement'], #12 Fundraising Announcement\n",
    "                   ['thank','support','shoutout','help','shout','question','mention'], #13 Appreciation\n",
    "                   ['confer','regist','live','symposium','stream','livestream','summit','co','founder','talk','speak','ceo','tomorrow'], #14 Conference and Summit\n",
    "                   ['hire','join','team','bring','welcom','work','appli','research','specialist','student','career','posit'],#15 Hiring Information\n",
    "                   ['congrat','congratul','list','award','winner','finalist','partner','prize'],#16 Congratulations\n",
    "                   ['check','post','paper','interview','articl','blog','news','break','read',\n",
    "                   'latest','watch','podcast','listen','episod','stori','coverag','campaign','video','singapor','discuss','vote','panel',\n",
    "                    'chat','scientist','report','ceo','media','bbc','present','innov']]#17 Media\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "model = guidedlda.GuidedLDA(n_topics=18,n_iter=200,random_state=1,refresh=10,alpha=0.1,eta=0.01)\n",
    "vectorizer = CountVectorizer(min_df = 1)\n",
    "X = vectorizer.fit_transform(topic_tweets)\n",
    "\n",
    "vocab = vectorizer.get_feature_names()\n",
    "word2id = dict((v,idx) for idx,v in enumerate(vocab))\n",
    "seed_topics = {}\n",
    "for t_id, st in enumerate(seed_topic_list):\n",
    "    for word in st:\n",
    "        seed_topics[word2id[word]] = t_id\n",
    "\n",
    "model.fit(X.toarray(),seed_topics=seed_topics,seed_confidence=0.65)\n",
    "topic_word = model.topic_word_\n",
    "n_top_words = 40\n",
    "vocab = tuple(vocab)\n",
    "\n",
    "for i, topic_dist in enumerate(topic_word):\n",
    "    print('\\n')\n",
    "    print('Topic:',i)\n",
    "    words_probability = np.array(-topic_dist)\n",
    "    for index in range(n_top_words):\n",
    "        print(round(abs(np.sort(words_probability))[:(n_top_words)][index],4),'*',\n",
    "              np.array(vocab)[np.argsort(topic_dist)][:-(n_top_words+1):-1][index],sep='',end='  ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of retweets in Other: 281\n",
      "the number of tweets that are less than 10 words 461\n"
     ]
    }
   ],
   "source": [
    "other_retweet = []\n",
    "other_not_retweet = []\n",
    "other_retweet_processed = []\n",
    "other_not_retweet_processed = []\n",
    "for index,i in other.iterrows():\n",
    "    if i['tweets'].startswith('RT:'):\n",
    "        other_retweet.append(i['tweets'])\n",
    "        other_retweet_processed.append(i['processed'])\n",
    "    else:\n",
    "        other_not_retweet.append(i['tweets'])\n",
    "        other_not_retweet_processed.append(i['processed'])\n",
    "print('the number of retweets in Other:',len(other_retweet))\n",
    "number = 0\n",
    "for i in other_not_retweet_processed:\n",
    "    if len(i.split())<10:\n",
    "        number +=1\n",
    "print('the number of tweets that are less than 10 words:',number)\n",
    "        \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
